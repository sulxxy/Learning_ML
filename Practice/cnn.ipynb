{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution\n",
    "Convolutional Neural Network (CNN) refers to the neural networks which contains at least one layer convolution operation. Convolution is a widely used operator in signal processing. In digital image processing, convolution is used to apply `filters` on the origin image, which is able to detect features, (un)sharp or even restore images.  In CNN, the filers can be learned automatically. Formally, a convolution in CNN can be written:\n",
    "$$ S(i, j) = (K* I)(i, j) = \\sum_m\\sum_nI(i-m, j-n)K(m, n)$$\n",
    "in which $I$ is origin image, $K$ is the kernel (i.e., filter), and $S$ is the output (a.k.a. feature map). Following example (from the book [Deep Learning](https://www.deeplearningbook.org/contents/convnets.html)) shows the computation procedure of convolution:\n",
    "![Convolution](./convolution.jpg)\n",
    "\n",
    "## Advantages\n",
    "There are several advantages of convolution. First of all, the number of parameters is much less than normal neural networks. The filters in common are not very large and the whole image will share those filters. Also, the convolution operation consider the surrounding information for each pixel. The MLP, however, treats each pixel as an individual input. Obviously CNN is more reasonable. Last but not least, one does not has to change the filters even though the input image size changed, but if using MLP, change of input size means change of parameter size.\n",
    "\n",
    "## Back Propagation\n",
    "The gradient of a convolution operation w.r.t. both data and weights is also a convolution operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling\n",
    "A convolution layer is usually followed with a pooling layer. Pooling layers are mainly used for downsampling and reducing the size of parameters. In practice, Max pooling outperforms average average pooling. \n",
    "\n",
    "## Back propagation\n",
    "For max pooling, the gradient of a pooling layer w.r.t. data (there's no weights in pooling layer) is the max value for the position of max value and zero for other position. In particular, there is no gradient with respect to non maximum values, since changing them slightly does not affect the output. Further the max is locally linear with slope 1, with respect to the input that actually achieves the max. Thus, the gradient from the next layer is passed back to only that neuron which achieved the max. All other neurons get zero gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc1 = nn.Linear(7*7*32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> total trainning batch number: 15000\n",
      "==>>> total testing batch number: 2500\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "num_classes = 10\n",
    "num_epoch = 10\n",
    "model = CNN(10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=True)\n",
    "print ('==>>> total trainning batch number: {}'.format(len(train_data_loader)))\n",
    "print ('==>>> total testing batch number: {}'.format(len(test_data_loader)))\n",
    "\n",
    "# train\n",
    "for epoch in range(num_epoch):\n",
    "    for i, (images, labels) in enumerate(train_data_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout and BatchNorm (and maybe some custom modules) behave differently during training and evaluation. You must let the model know when to switch to eval mode by calling .eval() on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=1568, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluation\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 99.05%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_data_loader:\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted==labels).sum().item()\n",
    "        \n",
    "    print('ACC: {}%'.format(100*correct/total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
